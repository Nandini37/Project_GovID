{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.95 ðŸš€ Python-3.9.16 torch-2.4.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
      "image 1/1 d:\\Github\\Project_GovID\\notebooks\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 886.5ms\n",
      "Speed: 300.3ms preprocess, 886.5ms inference, 443.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1md:\\Github\\Project_GovID\\static\\runs\\detect\\predict4\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\envs\\streamlit\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Anaconda\\envs\\streamlit\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\Github\\Project_GovID\\.venv\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 803, in entrypoint\n",
      "    model = YOLO(model, task=task)\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\ultralytics\\models\\yolo\\model.py\", line 23, in __init__\n",
      "    super().__init__(model=model, task=task, verbose=verbose)\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 145, in __init__\n",
      "    self._load(model, task=task)\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 297, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 906, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 833, in torch_safe_load\n",
      "    ckpt = torch.load(file, map_location=\"cpu\")\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\ultralytics\\utils\\patches.py\", line 86, in torch_load\n",
      "    return _torch_load(*args, **kwargs)\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\torch\\serialization.py\", line 1065, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\torch\\serialization.py\", line 468, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"D:\\Github\\Project_GovID\\.venv\\lib\\site-packages\\torch\\serialization.py\", line 449, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'yolo11n-seg.pt'\n"
     ]
    }
   ],
   "source": [
    "!yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"../static/aadhar/images\"\n",
    "LABELS_PATH = \"../static/aadhar/labels\"\n",
    "NOTES_PATH = \"../static/aadhar/notes.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 29; valid: 4; test: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "labels = os.listdir(LABELS_PATH)\n",
    "\n",
    "\n",
    "\n",
    "# Split data\n",
    "train, test = train_test_split(labels, test_size=0.15, shuffle=True)\n",
    "valid, test = train_test_split(test, test_size=0.2)\n",
    "\n",
    "print(f\"train: {len(train)}; valid: {len(valid)}; test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"../static/aadhar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '../static/aadhar/test/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/test/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train/images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\streamlit\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '../static/aadhar/test/images'"
     ]
    }
   ],
   "source": [
    "os.makedirs(f\"{prefix}/test/images\")\n",
    "os.makedirs(f\"{prefix}/test/labels\")\n",
    "os.makedirs(f\"{prefix}/train/images\")\n",
    "os.makedirs(f\"{prefix}/train/labels\")\n",
    "os.makedirs(f\"{prefix}/valid/images\")\n",
    "os.makedirs(f\"{prefix}/valid/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files_to_dir(files, dirname):\n",
    "    ct = 0\n",
    "    for label_filename in files:\n",
    "        image_filename = f\"{label_filename[:-4]}.png\"\n",
    "        if os.path.exists(f\"{IMAGES_PATH}/{image_filename}\"):\n",
    "            print(f\"{image_filename} , -> {label_filename}\")\n",
    "            ct = ct +1\n",
    "            print(f\"{dirname}/images/{image_filename}\")\n",
    "                  \n",
    "            shutil.copy(f\"{IMAGES_PATH}/{image_filename}\", f\"{dirname}/images/{image_filename}\")\n",
    "            shutil.copy(f\"{LABELS_PATH}/{label_filename}\", f\"{dirname}/labels/{label_filename}\")\n",
    "    print(ct)\n",
    "\n",
    "# Move splits to folders\n",
    "move_files_to_dir(train, \"../static/aadhar/train\")\n",
    "move_files_to_dir(test, \"../static/aadhar/test\")\n",
    "move_files_to_dir(valid, \"../static/aadhar/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ../static/aadhar/train/images\n",
      "test: ../static/aadhar/test/images\n",
      "val: ../static/aadhar/valid/images\n",
      "\n",
      "nc: 6\n",
      "names: ['name_value', 'gender_value', 'dob_key', 'dob_value', 'adhar_number_value', 'name_key']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "descr_darknet = json.load(open(NOTES_PATH))\n",
    "\n",
    "train_path = \"../static/aadhar/train/images\"\n",
    "test_path = \"../static/aadhar/test/images\"\n",
    "valid_path = \"../static/aadhar/valid/images\"\n",
    "\n",
    "nc = len(descr_darknet[\"categories\"])\n",
    "names = [category[\"name\"] for category in descr_darknet[\"categories\"]]\n",
    "\n",
    "print(\n",
    "    f\"train: {train_path}\\n\"\n",
    "    f\"test: {test_path}\\n\"\n",
    "    f\"val: {valid_path}\\n\\n\"\n",
    "    f\"nc: {nc}\\n\"\n",
    "    f\"names: {names}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../data.yaml\", \"w\") as file:\n",
    "    yaml.dump({\n",
    "        \"train\": train_path,\n",
    "        \"test\": test_path,\n",
    "        \"val\": valid_path,\n",
    "        \"nc\": nc,\n",
    "        \"names\": [f'{name}' for name in names]\n",
    "    }, stream=file, default_flow_style=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!yolo task=detect mode=train model=yolov8n.pt data=\"../data.yaml\" epochs=100 imgsz=800 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"D:/Github/Project_GovID/models/adhar-processor-yolov8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x800 1 adhar_number_value, 1238.0ms\n",
      "1: 800x800 1 adhar_number_value, 1 name_key, 1238.0ms\n",
      "Speed: 194.0ms preprocess, 1238.0ms inference, 97.5ms postprocess per image at shape (1, 3, 800, 800)\n"
     ]
    }
   ],
   "source": [
    "# Run batched inference on a list of images\n",
    "results = model([\"D:/Github/Project_GovID/static/aadhar/test/images/2.png\", \"D:/Github/Project_GovID/static/aadhar/test/images/6.png\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
